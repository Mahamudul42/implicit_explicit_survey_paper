\documentclass[acmsmall,screen]{acmart}

% Package imports
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{url}
\usepackage{hyperref}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{balance}
\usetikzlibrary{shapes.geometric,arrows,positioning,shapes.symbols}
\pgfplotsset{compat=1.18}

% ACM-specific formatting
\acmVolume{1}
\acmNumber{1}
\acmArticle{1}
\acmYear{2025}
\acmMonth{10}
\acmDOI{10.1145/3648406}

% Authors
\acmBooktitle{ACM Transactions on Recommender Systems}
\acmPrice{15.00}
\acmISBN{978-1-4503-XXXX-X/25/10}

\title{Implicit vs. Explicit Feedback in Recommender Systems: A Comprehensive Survey and Unified Framework}

\author{Mahamudul Hasan}
\affiliation{%
  \institution{University of Minnesota Twin Cities}
  \city{Minneapolis}
  \state{Minnesota}
  \country{USA}}
\email{hasan181@umn.edu}

% CCS Concepts
\ccsdesc[500]{Information systems~Recommender systems}
\ccsdesc[500]{Information systems~Personalization}
\ccsdesc[300]{Computing methodologies~Machine learning}
\ccsdesc[300]{Information systems~Collaborative filtering}
\ccsdesc[100]{Computing methodologies~Neural networks}

\keywords{Recommender Systems, Implicit Feedback, Explicit Feedback, Collaborative Filtering, Machine Learning, Hybrid Models, Evaluation Metrics, User Behavior}

\begin{document}

\begin{abstract}
Recommender systems have evolved into critical infrastructure for modern digital platforms, with user feedback serving as the fundamental data source driving personalization algorithms. This survey provides the first comprehensive analysis comparing implicit and explicit feedback mechanisms in recommender systems, establishing a unified theoretical framework and systematic evaluation methodology.

We present a comprehensive taxonomy that categorizes feedback along multiple dimensions: collection mechanism, signal quality, temporal characteristics, and user cognitive load. Through systematic analysis of 150+ research papers spanning 2010-2025, we identify key algorithmic paradigms, evaluation challenges, and emerging research directions. 

Our empirical meta-analysis of 45 studies reveals that hybrid approaches combining both feedback types typically achieve 15-32\% performance improvements over pure methods, demonstrating their complementary nature. While implicit feedback often provides abundant signals enabling real-time adaptation, its quality varies significantly by context—purchases indicate strong preference while clicks may reflect curiosity or accident. Conversely, explicit feedback typically offers higher precision in controlled settings, yet remains vulnerable to strategic behavior, rating inflation, and severe sparsity in practice.

Key contributions include: (1) A five-dimensional taxonomy unifying feedback characteristics; (2) Systematic analysis of algorithmic approaches across feedback types; (3) Bias-aware evaluation framework addressing feedback-specific challenges; (4) Empirical analysis of real-world deployment patterns across six major domains; (5) Comprehensive identification of ethical considerations and future research directions.

Our analysis reveals that the optimal feedback strategy depends critically on domain context, user characteristics, and system objectives—there is no universal "best" approach. We identify four critical research directions: privacy-preserving feedback collection, causal inference for bias mitigation, real-time multimodal integration, and fairness-aware recommendation. This work provides both theoretical foundations and practical guidance for developing next-generation recommender systems.
\end{abstract}

\maketitle

% Section restructuring for standard survey paper format
\input{sections/introduction}
\input{sections/related_work}
\input{sections/methodology}
\input{sections/evaluation}
\input{sections/applications}
\input{sections/challenges_future}
\input{sections/conclusion}
\input{sections/appendices}

\bibliographystyle{acm}
\bibliography{references}

\end{document}