
\appendix

\section{Mathematical Foundations}
\label{appendix:math}

This appendix provides essential mathematical formulations.

\subsection{Matrix Factorization}

\textbf{Basic Model}: $\mathbf{R} \approx \mathbf{P} \mathbf{Q}^T$ where $\mathbf{P} \in \mathbb{R}^{m \times k}$ (user factors) and $\mathbf{Q} \in \mathbb{R}^{n \times k}$ (item factors). Predicted rating: $\hat{r}_{ui} = \mu + b_u + b_i + \mathbf{p}_u^T \mathbf{q}_i$.

\textbf{Implicit Feedback (wALS)}: Confidence-weighted with $C_{ui} = 1 + \alpha r_{ui}$:
$$\mathcal{L} = \sum_{u,i} c_{ui} (p_{ui} - \mathbf{p}_u^T \mathbf{q}_i)^2 + \lambda \left( \sum_u \|\mathbf{p}_u\|^2 + \sum_i \|\mathbf{q}_i\|^2 \right)$$

\subsection{Bayesian Personalized Ranking}

Optimizes ranking: $\mathcal{L}_{BPR} = -\sum_{(u,i,j) \in D} \ln \sigma(\hat{r}_{ui} - \hat{r}_{uj})$

\subsection{Neural Collaborative Filtering}

Generalizes MF using neural networks: $\hat{r}_{ui} = f(\mathbf{p}_u, \mathbf{q}_i | \Theta)$ where $f$ is a multi-layer perceptron.

\section{Additional Resources}
\label{appendix:resources}

\subsection{Reproducibility and Datasets}

To facilitate reproducibility and further research, this section provides comprehensive information about benchmark datasets, their characteristics, and appropriate usage for different feedback types.

\begin{table}[h]
\centering
\tiny
\caption{Benchmark Datasets: Characteristics and Feedback Types}
\label{tab:datasets}
\begin{tabular}{@{}lccccl@{}}
\toprule
Dataset & Users & Items & Interactions & Feedback & Domain \\
\midrule
\multicolumn{6}{l}{\textit{\textbf{Explicit Feedback Datasets}}} \\
\midrule
MovieLens-100K & 943 & 1.7K & 100K & Ratings (1-5) & Movies \\
MovieLens-1M & 6K & 3.9K & 1M & Ratings (1-5) & Movies \\
MovieLens-25M & 162K & 59K & 25M & Ratings (0.5-5) & Movies \\
Netflix Prize & 480K & 18K & 100M & Ratings (1-5) & Movies \\
Book-Crossing & 278K & 271K & 1.1M & Ratings (1-10) & Books \\
Jester & 73K & 100 & 4.1M & Ratings (-10 to 10) & Jokes \\
\midrule
\multicolumn{6}{l}{\textit{\textbf{Implicit Feedback Datasets}}} \\
\midrule
Last.fm-360K & 360K & 290K & 17.5M & Listening count & Music \\
Last.fm-1K & 992 & 176K & 19.1M & Plays & Music \\
Spotify-1M & 1M & 160K & 1B+ & Streams & Music \\
Amazon (multi) & Varies & Varies & 233M & Purchases/views & E-commerce \\
Taobao & 987K & 4.1M & 100M & Clicks/purch. & E-commerce \\
Tmall & 425K & 1.1M & 54M & Actions & E-commerce \\
Pinterest & 55K & 9.9K & 1.5M & Pins & Social \\
Yelp & 1.9M & 192K & 8M & Check-ins & Local biz \\
\midrule
\multicolumn{6}{l}{\textit{\textbf{Hybrid (Explicit + Implicit) Datasets}}} \\
\midrule
Yelp Challenge & 1.9M & 192K & 8M ratings + & Both & Reviews \\
 & & & 1.2M reviews & & \\
Amazon Reviews & Varies & Varies & 233M ratings + & Both & E-commerce \\
 & & & text reviews & & \\
Epinions & 49K & 139K & 664K + trust & Both & Products \\
Douban & 129K & 58K & 17M + reviews & Both & Movies/Books \\
\midrule
\multicolumn{6}{l}{\textit{\textbf{Sequential/Temporal Datasets}}} \\
\midrule
YOOCHOOSE & -- & 53K & 34M & Clicks/purch. & E-commerce \\
RetailRocket & -- & 235K & 2.7M & Events & E-commerce \\
Diginetica & -- & 43K & 1M & Sessions & E-commerce \\
\bottomrule
\multicolumn{6}{l}{\scriptsize \textit{Note: Sizes approximate; some datasets have multiple versions.}} \\
\end{tabular}
\end{table}

\textbf{Dataset Selection Guidelines:}
\begin{itemize}
    \item \textbf{For Explicit Feedback Research}: MovieLens (all sizes), Netflix Prize, Book-Crossing
    \item \textbf{For Implicit Feedback Research}: Last.fm, Taobao, Pinterest, Spotify
    \item \textbf{For Hybrid Systems}: Yelp Challenge, Amazon Reviews (include text and ratings)
    \item \textbf{For Temporal/Sequential}: YOOCHOOSE, RetailRocket, Diginetica
    \item \textbf{For Cold-Start Studies}: MovieLens-25M, Amazon (high sparsity versions)
    \item \textbf{For Scalability Testing}: Netflix Prize, Spotify-1M, Amazon-full
\end{itemize}

\textbf{Data Access and Citation:}
\begin{itemize}
    \item MovieLens: \url{https://grouplens.org/datasets/movielens/}
    \item Amazon Reviews: \url{https://cseweb.ucsd.edu/~jmcauley/datasets.html}
    \item Last.fm: \url{https://www.last.fm/api}
    \item Yelp Challenge: \url{https://www.yelp.com/dataset}
    \item RecSysDatasets: \url{https://github.com/caserec/Datasets-for-Recommender-Systems}
\end{itemize}

\textbf{Preprocessing Recommendations:}
\begin{itemize}
    \item \textbf{Minimum Interactions}: Filter users/items with $<$5 interactions for explicit, $<$20 for implicit
    \item \textbf{Temporal Splits}: Use time-based train/test splits (80/20) rather than random
    \item \textbf{Cold-Start Simulation}: Reserve 10-20\% of users/items with limited data for cold-start evaluation
    \item \textbf{Negative Sampling}: For implicit feedback, sample negatives from unobserved items (typical ratio 1:4 or 1:10)
\end{itemize}

\subsection{Open-Source Implementations}
\begin{itemize}
    \item \textbf{Surprise}: Python scikit for recommender systems
    \item \textbf{LightFM}: Hybrid recommendation algorithms
    \item \textbf{RecBole}: Comprehensive recommendation library
    \item \textbf{TensorFlow Recommenders}: Production-scale implementations
\end{itemize}

\subsection{Benchmark Datasets}
\begin{itemize}
    \item \textbf{MovieLens}: Multiple scales (100K, 1M, 10M, 25M ratings)
    \item \textbf{Amazon Product Reviews}: Multi-category e-commerce data
    \item \textbf{Netflix Prize}: Historical movie ratings dataset
    \item \textbf{Last.fm}: Music listening data with implicit feedback
    \item \textbf{Yelp Challenge}: Business reviews and check-ins
\end{itemize}

\subsection{Research Venues}
\textbf{Top Conferences}: ACM RecSys, KDD, WWW, SIGIR, WSDM, CIKM

\textbf{Key Journals}: ACM TOIS, IEEE TKDE, ACM TIST, User Modeling and User-Adapted Interaction

\subsection{Online Resources}
\begin{itemize}
    \item RecSys Wiki: \texttt{wiki.recsyschallenge.com}
    \item Papers with Code: \texttt{paperswithcode.com/task/recommendation-systems}
    \item Awesome Recommender Systems: \texttt{github.com/grahamjenson/list\_of\_recommender\_systems}
\end{itemize}
